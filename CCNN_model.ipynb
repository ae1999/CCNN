{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm.contrib import tzip\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "buried-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels = 1, out_channels = 1, debug = False):\n",
    "        \n",
    "        super(CCNN, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        ## encode:\n",
    "        \n",
    "        self.c_0 = nn.Sequential(*[nn.Conv2d(in_channels = self.in_channels, out_channels = 32,\n",
    "                                            kernel_size=11, padding=5, stride=1)])\n",
    "        \n",
    "        self.c_1 = nn.Sequential(*[nn.Conv2d(in_channels = 32, out_channels = 32,\n",
    "                                            kernel_size=7, padding=3, stride=1)])\n",
    "        \n",
    "        self.c_2 = nn.Sequential(*[nn.Conv2d(in_channels = 32, out_channels = 64,\n",
    "                                            kernel_size=5, padding=3, stride=1)])\n",
    "        \n",
    "        self.c_3 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = 1000,\n",
    "                                            kernel_size=1, padding=0, stride=1)])\n",
    "        \n",
    "        self.c_4 = nn.Sequential(*[nn.Conv2d(in_channels = 1000, out_channels = 400,\n",
    "                                            kernel_size=1, padding=0, stride=1)])\n",
    "        \n",
    "        self.c_5 = nn.Sequential(*[nn.Conv2d(in_channels = 400, out_channels = self.out_channels,\n",
    "                                            kernel_size=1, padding=0, stride=1)])\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        debug = self.debug\n",
    "\n",
    "        ## encode:\n",
    "        size0 = x.size()\n",
    "        x = self.c_0(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        size1 = x.size()\n",
    "        \n",
    "        x = self.c_1(x)\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        size2 = x.size()\n",
    "        \n",
    "        x = self.c_2(x)\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        size3 = x.size()\n",
    "        \n",
    "        x = self.c_3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        size4 = x.size()\n",
    "        \n",
    "        x = self.c_4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        size5 = x.size()\n",
    "        \n",
    "        x = self.c_5(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        size6 = x.size()\n",
    "        \n",
    "        if debug:\n",
    "            print(\"size: {}\".format(size1))\n",
    "            print(\"size: {}\".format(size2))\n",
    "            print(\"size: {}\".format(size3))\n",
    "            print(\"size: {}\".format(size4))\n",
    "            print(\"size: {}\".format(size5))\n",
    "            print(\"size: {}\".format(size6))\n",
    "            \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, criterion, optimizer, NUM_EPOCHS = 30, log = True, load = False):\n",
    "    \n",
    "    criterion0 = torch.nn.MSELoss()\n",
    "    print('Epochs:\\t', NUM_EPOCHS)\n",
    "    if load:\n",
    "        model = CCNN()\n",
    "        model.load_state_dict(torch.load(\"./model_best.pth\"))\n",
    "    \n",
    "    losses = []\n",
    "    t_losses = []\n",
    "    mseLosses = []\n",
    "    mse_t_losses = []\n",
    "    prev_loss = float('inf')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loss_f = []\n",
    "        mseLoss_f = []\n",
    "        t_start = time.time()\n",
    "\n",
    "        for i, (input_tensor, target_tensor) in enumerate(train_loader):\n",
    "            \n",
    "            input_tensor = torch.autograd.Variable(input_tensor)\n",
    "            target_tensor = torch.autograd.Variable(target_tensor)\n",
    "            target_tensor = torch.unsqueeze(target_tensor, 1)\n",
    "            \n",
    "            predicted_tensor = model(input_tensor)\n",
    "            \n",
    "            loss = criterion(predicted_tensor, target_tensor)\n",
    "            mseLoss = criterion0(predicted_tensor, target_tensor)\n",
    "            if log: print('batch loss:', float(loss))\n",
    "            if log: print('batch MSE loss:', float(mseLoss))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_f.append(float(loss))\n",
    "            mseLoss_f.append(float(mseLoss))\n",
    "\n",
    "        delta = time.time() - t_start\n",
    "        \n",
    "        dataiter = iter(test_loader)\n",
    "        images, label = dataiter.next()\n",
    "        input_tensor = torch.autograd.Variable(images)\n",
    "        target_tensor = torch.autograd.Variable(label)\n",
    "        predicted_tensor = model(input_tensor)\n",
    "        target_tensor = torch.unsqueeze(target_tensor, 1)\n",
    "        test_loss = criterion(predicted_tensor, target_tensor)\n",
    "        mse_test_loss = criterion0(predicted_tensor, target_tensor)\n",
    "    \n",
    "        if np.array(loss_f).mean() < prev_loss:\n",
    "            prev_loss = np.array(loss_f).mean()\n",
    "            torch.save(model.state_dict(), './model_best.pth')\n",
    "        \n",
    "        losses.append(np.array(loss_f).mean())\n",
    "        t_losses.append(float(test_loss))\n",
    "        mseLosses.append(np.array(mseLoss_f).mean())\n",
    "        mse_t_losses.append(float(mse_test_loss))\n",
    "        print('test MSE Loss:', float(mse_test_loss))\n",
    "        print(\"Epoch #{}\\ttrain loss: {:.8f}\\ttest loss: {:.8f}\\t Time: {:2f}s\".format(epoch+1, np.array(loss_f).mean(),t_losses[-1], delta))\n",
    "        \n",
    "    return losses, t_losses, mseLosses, mse_t_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(test_loader, model = None, model_path = ''):\n",
    "    correctnesses = []\n",
    "    if len(model_path):\n",
    "        model = CCNN()\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()\n",
    "    images = []\n",
    "    labels = []\n",
    "    results = []\n",
    "    \n",
    "    i = 0\n",
    "    for img, label in test_loader:\n",
    "        if i > 10:\n",
    "            break\n",
    "        i += 1\n",
    "        img = img[0].to(device)\n",
    "        label = label[0].cpu().numpy()\n",
    "        label = label.squeeze()\n",
    "        output = model(img)\n",
    "        #a = 1 - torch.count_nonzero((torch.argmax(class_prob, axis = 1)-torch.tensor(label)))/(360*480)\n",
    "        model_output = output #dr.rev_translate(torch.argmax(class_prob, axis = 1))\n",
    "        \n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        results.append(model_output)\n",
    "        #correctnesses.append(a)\n",
    "    return images, labels, results#, correctnesses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_x86",
   "language": "python",
   "name": "pytorch_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
